{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3349dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "# sqlalchemy connects to MySQL database using the pymysql driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524a258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configura√ß√£o da Conex√£o (A String de Conex√£o Profissional)\n",
    "# Formato: mysql+driver://usuario:senha@host/banco\n",
    "connection_string = \"mysql+pymysql://user_analista:senha_analista@localhost/telecom_churn_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3894b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Criar a \"Engine\" (O Motor de Conex√£o)\n",
    "# Isso gerencia conex√µes abertas/fechadas automaticamente para voc√™.\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e382feb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Extraindo dados via SQLAlchemy...\n"
     ]
    }
   ],
   "source": [
    "# 1. Defina a Query (A pergunta ao banco)\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    c.id_cliente,\n",
    "    c.genero,\n",
    "    TIMESTAMPDIFF(YEAR, c.data_nascimento, CURDATE()) AS idade,\n",
    "    c.estado,\n",
    "    a.plano,\n",
    "    a.valor_mensal,\n",
    "    TIMESTAMPDIFF(MONTH, a.data_inicio, CURDATE()) AS meses_contrato,\n",
    "    AVG(u.dados_consumidos_gb) AS media_consumo_gb,\n",
    "    SUM(u.chamadas_suporte) AS total_chamadas_suporte,\n",
    "    CASE WHEN a.status = 'Cancelado' THEN 1 ELSE 0 END AS churn\n",
    "FROM clientes c\n",
    "JOIN assinaturas a ON c.id_cliente = a.id_cliente\n",
    "LEFT JOIN uso_servico u ON c.id_cliente = u.id_cliente\n",
    "GROUP BY \n",
    "    c.id_cliente, c.genero, c.data_nascimento, c.estado, \n",
    "    a.plano, a.valor_mensal, a.data_inicio, a.status;\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚è≥ Extraindo dados via SQLAlchemy...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64edb2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Erro na conex√£o: 'cryptography' package is required for sha256_password or caching_sha2_password auth methods\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # O Pandas ama o SQLAlchemy. √â a integra√ß√£o nativa perfeita.\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(f\"‚úÖ Sucesso Absoluto! Dataset carregado com {df.shape[0]} linhas.\")\n",
    "    display(df.head()) # Se der erro no display, use print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na conex√£o: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df822322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an√°lise explorat√≥ria r√°pida\n",
    "print(\"üìä An√°lise Explorat√≥ria R√°pida:\")\n",
    "print(\"--- Info do DataFrame ---\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n--- Contagem de Valores Nulos ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n--- Estat√≠sticas Descritivas ---\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9ee03b",
   "metadata": {},
   "source": [
    "#### Treinar e Avaliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faabe808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. PREPARA√á√ÉO DOS DADOS (Feature Engineering + Pr√©-processamento)\n",
    "print(\"üßπ Preparando os dados...\")\n",
    "\n",
    "# Garantir que o df est√° limpo e pronto para o modelo\n",
    "# Selecionar apenas as colunas relevantes para o modelo\n",
    "X = df.drop(columns=['id_cliente', 'churn'])\n",
    "y = df['churn'].astype(int)\n",
    "\n",
    "# Dividir Treino e Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Definir quais colunas s√£o o que\n",
    "numeric_features = ['idade', 'valor_mensal', 'meses_contrato', 'media_consumo_gb', 'total_chamadas_suporte']\n",
    "categorical_features = ['genero', 'estado', 'plano']\n",
    "\n",
    "# Criando os processadores usando make_pipeline para cada tipo de dado\n",
    "numeric_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value=0),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "# Para as vari√°veis categ√≥ricas, usaremos o OneHotEncoder para criar dummies\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(handle_unknown='ignore', sparse_output=False) # sparse_output=False facilita visualiza√ß√£o\n",
    ")\n",
    "\n",
    "# O Pr√©-processador Mestre\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    remainder='drop' # Ignora outras colunas se houver\n",
    ")\n",
    "\n",
    "# O Modelo Final (Random Forest)\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    ")\n",
    "\n",
    "# 3. TREINAMENTO E AVALIA√á√ÉO \n",
    "print(\"üöÄ Iniciando treinamento do modelo...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Treinamento conclu√≠do! Fazendo previs√µes...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 4. RESULTADOS \n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"üìä RELAT√ìRIO DE PERFORMANCE DO MODELO\")\n",
    "print(\"=\"*40)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nüîç Matriz de Confus√£o (Acertos vs Erros):\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
